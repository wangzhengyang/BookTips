[toc]
# 线程间共享数据问题
所有线程间共享数据的问题，都是修改数据导致的。**如果所有的共享数据都是只读的，就没有问题，因为一个线程所读取的数据不受另一个线程是否正在读取相同的数据而影响**

一个被广泛用来帮助程序员推导代码的概念，就是**不变量(invariants)**，这些不变量经常在更新中被打破，尤其是在数据结构比较复杂或是更新需要修改超过一个值时

修改线程之间共享数据的最简单的潜在问题就是破坏不变量
并发代码中错误的最常见原因之一：**竞争条件(race condition)**

## 竞争条件
在并发性中，竞争条件就是结果取决于两个或更多线程上的操作执行的相对顺序的一切事物。线程竞争执行各自的操作。在大多数情况下，这是比较良性的，因为所有可能的结果都是可以接受的，尽管他们可能会随着不同的相对顺序而改变。**竞争条件(race condition)** 通常用来表示**有问题的**的竞争条件

## 避免有问题的竞争条件
最简单的选择是用保护机制封装你数据结构，以确保只有实际执行修改的线程能够在不变量损坏的地方看到中间数据。从其他访问该数据结构线程的角度看，这种修改要么还没开始要么已完成

另一种设计是修改数据结构的设计及其不变量，从而令修改作为一系列不可分割的变更来完成，每个修改均保留其不变量。这通常称为**无锁编程(lock-free programming)**

处理竞争条件的令一种方式将对数据结构的更新作为一个**事务(transaction)**来处理。所需的一系列数据修改和读取被存储在一个事务日志中，然后在单个步骤中进行提交。如果该提交因为数据结构已被另一个线程修改而无法进行，该事务将重新启动。这称为**软件事务内存(software transactional memory，STM)**

C++标准提供的保护共享数据的最基本机制是**互斥元(mutex)**

# 互斥元保护共享数据
在访问共享数据结构之前，**锁定(lock)**与该数据相关的互斥元，当访问数据结构完成后，**解锁(unlock)**该互斥元。线程库会确保一旦一个线程已经锁定某个互斥元，所有其他试图锁定相同互斥元的线程必须等待，直到成功锁定了该互斥元的线程解锁此互斥元

## C++的互斥元
通过`std::mutex`的实例创建互斥元，调用成员函数`lock()`来锁定它，调用成员函数`unlock()`来解锁它。但直接调用成员函数是不推荐的做法，因为这意味着必须记住在离开函数的每条代码路径都调用`unlock()`，包括由于异常所导致的在内。作为替代，标准C++库提供了`std::lock_guard`类模板，实现了互斥元的RAII管用语法；它在构造时锁定所给的互斥元，在析构时将互斥元解锁，从而保证被锁定的互斥元始终被正确解锁
```c++
#include <list>
#include <mutex>
#include <algorithm>

std::list<int> some_list;
std::mutex some_mutex;

void add_to_list(int new_value)
{
    std::lock_gurad<std::mutex> guard(some_mutex);
    some_list.push_back(new_value);
}

bool list_contains(int value_to_find)
{
    std::lock_guard<std::mutex> guard(some_mutex);
    return std::find(some_list.begin(), some_list.end(), value_to_find) != some_list.end();
}
```
在大多数情况下，在类中将互斥元和受保护的数据组织在一起，这是一个标准的面向对象应用程序设计原则，通过将它们放在一个类中，清除地标记他们是相关的，还可以封装函数以及强制保护。

如果其中一个成员函数返回对受保护数据的指针或引用，那么所有成员函数都以良好顺序的方式锁定互斥元也是没关系的，因为已经在保护中出现问题，**能够访问(并可能修改)该指针或引用的任意代码现在可以访问受保护的数据而无需锁定该互斥元**

## 为保护数据精心组织代码
```c++
class some_data
{
    int a;
    std::string b;
public:
    void do_something();
};

class data_wrapper
{
private:
    some_data data;
    std::mutex m;
public:
    template<typename Function>
    void process_data(Function func)
    {
        std::lock_guard<std::mutex> l(m);
        func(data);
    }
};

some_data* unprotected;
void malicious_funcition(some_data& protected_data)
{
    unprotected = &protected_data;
}

data_wrapper x;
void foo()
{
    x.process_data(malicious_function);
    unprotected->do_something();
}
```
**不要将受保护数据的指针和引用传递到锁的范围之外，无论是通过从函数中返回它们、将其存放在外部可见的内存中，还是作为参数传递给用户提供的函数**

## 发现接口中固有的竞争条件
```c++
template <typename T, typename Container=std::deque<T>>
class stack{
public:
    explicit stack(const Container&);
    explicit stack(Container&& = Container());
    template <class Alloc> explicit stack(const Alloc&);
    template <class Alloc> stack(const Container&, const Alloc&);
    template <class Alloc> stack(Container&&, const Alloc&);
    template <class Alloc> stack(stack&&, const Alloc&);
    bool empty() const;
    size_t size() const;
    T& top();
    T const& top() const;
    void push(T const&);
    void push(T&&);
    void pop();
    void swap(stack&&);
};
```
`empty()`的结果和`size()`不可靠，因为其他线程可以自由地访问堆栈，并且可能`push()`新元素入栈或`pop()`已有的元素出栈

```c++
stack<int> s;
if(!s.empty())
{
    int const value = s.top();
    s.pop();
    do_something(value);
}
```
如果该stack实例是非共享的，如果栈非空，检查empty()并调用top()访问顶部元素是安全的，但对于共享的stack对象，**这个调用序列不再安全**

发生这种问题是接口设计的后果，所以解决方法就是改变接口

线程安全堆栈的示范
```c++
#include <exception>
#include <memory>
struct empty_stack : std::exception
{
    const char* what() const throw();
};

template <typnename T>
class threadsafe_stack{
public:
    threadsafe_stack();
    threadsafe_stack(const threadsafe_stack&);
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value);
    std::shared_ptr<T> pop();
    void pop(T& value);
    bool empty() const;
};
```
通过削减接口，考虑到最大的安全性，甚至对整个堆栈的操作都受到限制
```c++
#include <exception>
#include <memory>
#include <mutex>
#include <stack>

struct empty_stack : std::exception
{
    const char* what() const throw();
};

template <typename T>
class threadsafe_stack
{
private:
    std::vector<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack(){}
    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data=other.data;
    }
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
    
    void push(T new_value){
        std::lock_guard<std::mutex> lock(m);
        data.push(new_value);
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        std::shared_ptr<T> const res(std::make_shared<T>(data.top()));
        data.pop();
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value = data.top();
        data.pop();
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```
这个栈的实现实际上是**可复制的(copyable)**——源对象中的拷贝构造函数锁定互斥元，然后复制内部栈

## 死锁：问题和解决方案
一对线程中的每一个都需要同时锁定两个互斥元来执行一些操作，并且每个线程都拥有一个互斥元，同时等待另一个。线程都无法继续，因为每个线程都在等待另一个释放其互斥元。这种情况称为**死锁(deadlock)**

为了避免死锁，常见建议是始终使用相同的顺序锁定这两个互斥元

C++标准库中的`std::lock`可以解决这一问题，`std::lock`函数可以同时锁定两个或更多的互斥元，而没有死锁的风险
```c++
class some_big_object;
void swap(some_big_object& lhs, some_big_object& rhs);

class X
{
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X(some_big_object const& sd) : some_detail(sd){}
    friend void swap(X& lhs, X& rhs)
    {
        if(&lsh == &rhs){
            return;
        }
        std::lock(lhs.m, rhs.m);
        std::lock_guard<std::mutex> lock_a(lhs.m, std::adopt_lock);
        std::lock_guard<std::mutex> lock_b(rhs.m, std::adopt_lock);
        swap(lhs.some_detail, rhs.some_detail);
    }
};
```
首先，检查参数以确保它们是不同的实例，因为试图在已经锁定了的`std::mutex`上获取锁，是未定义的行为；然后，调用`std::lock()`锁住这两个互斥元，同时构造两个`std::lock_guard`的实例，每个实例对应一个互斥元。额外提供一个参数`std::adopt_lock`给互斥元，告知`std::lock_guard`对象该互斥元已被锁定，并且它们只应沿用互斥元上已有锁的所有权，而不是试图在构造函数中锁定互斥元

## 避免死锁指南
1. 避免嵌套锁
如果已经持有一个锁，就别再获取锁
2. 在持有锁时，避免调用用户提供代码
因为代码是用户提供的，所以你并不知道它会做什么
3. 以固定顺序获取锁
如果绝对需要获取两个或更多的锁，并且不能以`std::lock`的单个操作取得，次优的做法是在每个线程中以相同的顺序获取它们
4. 使用锁层次
其思路是将应用层分层，并且确认所有能够在任意给定的层级上被锁定的互斥元。当代码试图锁定一个互斥元时，如果它在较低层已经持有锁定，那么就不允许它锁定该互斥元
```c++
hierarchical_mutex high_level_mutex(10000);
hierarchical_mutex low_level_mutex(5000);

int do_low_level_stuff();

int low_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(low_level_mutex);
    return do_low_level_stuff();
}

void high_level_stuff(int some_param);
void high_level_func()
{
    std::lock_guard<hierarchical_mutex> lk(high_level_mutex);
    high_level_stuff(low_level_func());
}

void thread_a()
{
    high_level_func();
}

hierarchical_mutex other_mutex(100);
void do_other_stuff();
void other_stuff()
{
    high_level_func();
    do_other_stuff();
}

void thread_b()
{
    std::loc_guard<hierarchical_mutex> lk(other_mutex);
    other_stuff();
}
```
`thread_a()`遵守了规则，所以它运行良好，另一方面，`thread_b()`无视了规则，因此将在运行时失败

```c++
//简单的分层次互斥元
class hierarchical_mutex
{
    std::mutex internal_mutex;
    unsigned long const hierarychy_value;
    unsigned long previous_hierarychy_value;
    static thread_local unsigned long this_thread_hierarchy_value;

    void check_for_hierarchy_violation()
    {
        if(this_thread_hierarchy_value <= hierarchy_value){
            throw std::logic_error("mutex hierarchy violated");
        }
    }

    void update_hierarchy_value()
    {
        previous_hierarchy_value = this_thread_hierarchy_value;
        this_thread_hierarchy_value = hierarchy_value;
    }
public:
    explicit hierarchical_mutex(unsigned long value):hierarchy_value(value), previous_hierarchy_value(0){}
    void lock(){
        check_for_hierarchy_violation();
        internal_mutex.lock();
        update_hierarchy_value();
    }

    void unlock(){
        this_thread_hierarchy_value = previous_hierarchy_value;
        internal_mutex.unlock();
    }

    bool try_lock(){
        check_for_hierarchy_violation();
        if(!internal_mutex.try_lock()){
            return false;
        }

        update_hierarchy_value();
        return true;
    }
};

thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX);
```
使用`thread_local`的值来表示当前线程的层次值：`this_thread_hierarchy_value`。它被初始化为最大值，所以在刚开始的时候任意互斥元都可以被锁定。由于它被声明为`thread_local`，每个线程都有属于自己的副本，所以在一个线程中该变量的状态，完全独立于从另一个线程中读取的该变量的状态

## 用`std::unique_lock`灵活锁定
`std::unique_lock`比`std::lock_guard`提供了更多的灵活性，一个`std::unique_lock`实例并不总是拥有与之相关联的互斥元。首先，就像你可以把`std::adopt_lock`作为第二参数传递给构造函数，以便让锁对象来管理互斥元上的锁那样，也可以把`std::defer_lock`作为第二参数，来表示该互斥元在构造时应保持未被锁定
```c++
class some_big_object;
void swap(some_big_object& lhs, some_big_object& rhs);

class X
{
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X(some_big_object const& sd):some_big_object(sd){}
    friend void swap(X& lhs, X& rhs)
    {
        if(&rhs == & rhs){
            return;
        }
        std::unique_lock<std::mutex> lock_a(lhs.m, std::defer_lock);
        std::unique_lock<std::mutex> lock_b(rhs.m, std::defer_lock);
        std::lock(lock_a, lock_b);
        swap(lhs.some_detail, rhs.some_detail);
    }
};
```
`std::unique_lock`对象大小通常大于`std::lock_guard`对象，并且相比于`std::lock_guard`，使用`std::unique_lock`的时候，会有些许性能损失，因为需要对标识进行相应的更新检查。如果`std::lock_guard`足以满足要求，优先使用它。

## 在作用域之间转移锁的所有权
因为`std::unique_lock`实例并没有拥有与其相关的互斥元，互斥元的所有元可以在实例之间进行移动。在某些情况下，这种转移是自动的

允许函数锁定一个互斥元，并将此锁的所有权转移给调用者，于是调用者接下来可以在同一个锁的保护下执行额外的操作
```c++
std::unique_lock<std::mutex> get_lock()
{
    extern std::mutex some_mutex;
    std::unique_lock<std::mutex> lk(some_mutex);
    prepare_data();
    return lk;
}
void process_data()
{
    std::unique_lock<std::mutex> lk(get_lock());
    do_something();
}
```

